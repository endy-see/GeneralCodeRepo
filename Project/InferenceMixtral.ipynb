#!/bin/bash
# 定义输入模型列表
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10"  # version2
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10_again"  # version3 - bad -deleted
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10_test"  # version4 good
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_Zifandata_v1"
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10_test_v1"
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10_test_v2"
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10_test_v4"
# source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/mixtral_crowd_label_v1"
source_model_dir="/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/mixtral_crowd_master_label_v1"

# 定义输入文件列表
# input_file_names=("scrapekr1.2_spamllm2.4.parquet" "test_dataset_2024_03_05.tsv" "spamgtx5.0_UHRSoutput.parquet" "Clean_60k.tsv" "8k_with_flipped_labels.tsv")
# input_file_names=("spamgtx5.0_UHRSoutput.parquet")
# input_file_names=("scrapekr1.2_spamllm2.4_UrlExpectedLabel_escape.tsv" "test_dataset_2024_03_05_escape.tsv" "spamgtx5.0_UHRSoutput_escape.tsv" "Clean_60k_escape.tsv" "8k_with_flipped_labels_escape.tsv" "auditor_ym_escape1.tsv") # from zifan

# input_file_names=("scrapekr1.2_spamllm2.4_UrlExpectedLabel_escape.tsv")
# input_file_names=("Clean_60k.tsv")
input_file_names=("auditor_ym_escape1.tsv")

# test many models to get the best performance model
# for i in {9000..9800..200};do
#     # 创建一个新的目录
#     # mkdir "$source_model_dir/target_${i}"

#     # 移动模型文件
#     # mv "$source_model_dir/pytorch_model_${i}.bin" "$source_model_dir/target_${i}/pytorch_model.bin"
#     # cp "/cosmos/local/IndexQuality/FinetuneLLM/FullTrainTest/Mixtral_New_ym_bs_10/target/config.json" "$source_model_dir/target_${i}/config.json"
#     # os.popen(f'cp {args.load_from}/config.json {checkpoint_dir}')

#     # --input_file /cosmos/local/IndexQuality/FinetuneLLM/EvaluationSets/${input_file_name} \

#     echo "Current model is: model_${i}"
#     for input_file_name in "${input_file_names[@]}"; do
#         # 拷贝config.json
#         cp "/cosmos/local/IndexQuality/FinetuneLLM/Mixtral-8x7B-Instruct-v0.1/config.json" "$source_model_dir/model_${i}/config.json"
#         # 记录当前文件名
#         echo "Current processing file is: ${input_file_name}..."
#         # 执行命令
#         export CUDA_VISIBLE_DEVICES="1,2,3"
#         NCCL_DEBUG=WARN python -m torch.distributed.run  \
#         --nnodes 1 --nproc_per_node 3 inf_multi_mixtral_model_test_5.py \
#         --load_from "$source_model_dir/model_${i}" \
#         --input_file /cosmos/local/users/zifanwang/SpamLLM/data/${input_file_name} \
#         --output_file "$source_model_dir/model_${i}"/${input_file_name} \
#         --batch_size 12 \
#         --max_seq_length 1024 \
#         --cur_model_num ${i}
#     done

    # predict zifan's training data
    # echo "Current model is: model_${i}"
    # for input_file_name in "${input_file_names[@]}"; do
    #     # 记录当前文件名
    #     echo "Current processing file is: ${input_file_name}..."
    #     # 执行命令
    #     export CUDA_VISIBLE_DEVICES="0,1,2"
    #     NCCL_DEBUG=WARN python -m torch.distributed.run  \
    #     --nnodes 1 --nproc_per_node 3 inf_multi_mixtral_model_test_5.py \
    #     --load_from "$source_model_dir/current_best_${i}" \
    #     --input_file /local/users/zifanwang/CBSpam/data/SpamLLM_Output_ScrapeKR1.2_EvalSet_v4.tsv \
    #     --output_file "$source_model_dir/current_best_${i}"/${input_file_name} \
    #     --batch_size 12 \
    #     --cur_model_num ${i}
    # done
# done

i=3600
echo "Current model is: model_${i}"
for input_file_name in "${input_file_names[@]}"; do
    # 记录当前文件名
    echo "Current processing file is: ${input_file_name}..."
    # 执行命令
    export CUDA_VISIBLE_DEVICES="1,2,3"
    NCCL_DEBUG=WARN python -m torch.distributed.run  \
    --nnodes 1 --nproc_per_node 3 inf_multi_mixtral_model_test_5.py \
    --load_from "$source_model_dir/current_best_${i}" \
    --input_file /cosmos/local/users/zifanwang/SpamLLM/data/${input_file_name} \
    --output_file "$source_model_dir/current_best_${i}/${input_file_name}_new_scrapekr_expected_label" \
    --batch_size 12 \
    --cur_model_num ${i}
done

# Debug Panashe's inference bug
# i=1900
# echo "Current model is: model_${i}"
# for input_file_name in "${input_file_names[@]}"; do
#     # 记录当前文件名
#     echo "Current processing file is: ${input_file_name}..."
#     # 执行命令
#     export CUDA_VISIBLE_DEVICES="1,2,3"
#     NCCL_DEBUG=WARN python -m torch.distributed.run  \
#     --nnodes 1 --nproc_per_node 3 inf_multi_mixtral_model_test_5.py \
#     --load_from "$source_model_dir/current_best/" \
#     --input_file /cosmos/local/IndexQuality/FinetuneLLM/EvaluationSets/${input_file_name} \
#     --output_file "$source_model_dir/current_best/${input_file_name}_new_test_spamgtx" \
#     --batch_size 12 \
#     --cur_model_num ${i}
# done
